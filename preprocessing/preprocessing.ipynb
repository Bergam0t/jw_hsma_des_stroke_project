{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "398ec2a2",
   "metadata": {},
   "source": [
    "# Parameter and Distribution Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6fa055",
   "metadata": {},
   "source": [
    "This notebook helps to discover the correct distributions, and parameters for these distributions, to best approximate your real-world system in the model. \n",
    "\n",
    "As the model relies on random sampling of realistic values, ensuring that it knows what a 'realistic value' is is crucial. \n",
    "\n",
    "This notebook helps to generate distributions for \n",
    "- inter-arrival times (in hours and out of hours)\n",
    "- length of stay (subset by modified rankin scale (MRS) score on presentation and stroke type)\n",
    "- MRS score on presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44440d81",
   "metadata": {},
   "source": [
    "## Data Path Setup\n",
    "\n",
    "### LOS Data\n",
    "\n",
    "Please pass in a .csv file with the following columns: \n",
    "\n",
    "- Diagnosis *(text label or integer values)*\n",
    "- MRS *(integer values between 0 and 6)*\n",
    "- LOS *(integer number of days)*\n",
    "\n",
    "### IAT setup\n",
    "\n",
    "Please pass in a .csv file with the following columns: \n",
    "\n",
    "- in-hours *(integer number of minutes between arrivals)*\n",
    "- out-of-hours *(integer number of minutes between arrivals)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e4f3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE THIS IF YOUR FILE IS CALLED SOMETHING DIFFERENT OR STORED SOMEWHERE ELSE\n",
    "los_csv_file_path = \"../input_data/los.csv\"\n",
    "iat_csv_file_path = \"../input_data/iat.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adc53ac",
   "metadata": {},
   "source": [
    "The following should only be adjusted by advanced users. \n",
    "These parameters affect the tolerance of the script to recommending the exponential distribution if it is a 'good enough' approximation of the provided data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625dac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSOLUTE_GOOD = 0.005     # below this, fits are effectively perfect\n",
    "RELATIVE_TOL = 1.5      # 50% worse than best allowed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3edaa2",
   "metadata": {},
   "source": [
    "Now click 'Run All'. \n",
    "\n",
    "Three files will be generated in this folder providing the suggested distributions and parameters for your simulation. \n",
    "\n",
    "These should be used to update the\n",
    "- parameters in the file src/stroke_ward_model/inputs.py\n",
    "- distributions in the file src/stroke_ward_model/distributions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c71263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from distfit import distfit\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b69e8fd",
   "metadata": {},
   "source": [
    "# Length of Stay Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2286f0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "los_df = pd.read_csv(los_csv_file_path)\n",
    "\n",
    "results = []\n",
    "plots = []\n",
    "\n",
    "for diagnosis in los_df[\"diagnosis\"].unique():\n",
    "    los_df_diagnosis = los_df[los_df[\"diagnosis\"]==diagnosis]\n",
    "\n",
    "    fig = px.histogram(los_df_diagnosis.sort_values('mrs'),x=\"los\", facet_col=\"mrs\",title=diagnosis)\n",
    "    fig.update_yaxes(matches=None, showticklabels=True)\n",
    "\n",
    "    plots.append(fig)\n",
    "\n",
    "    for mrs in los_df_diagnosis[\"mrs\"].unique():\n",
    "        los_df_diagnosis_mrs = los_df_diagnosis[los_df_diagnosis[\"mrs\"]==mrs]\n",
    "\n",
    "        # Limit these to key distributions available in the sim-tools package\n",
    "        dfit = distfit(todf=True, distr=['norm', 'expon', 'pareto', 'weibull', 'gamma', 'lognorm', 'beta'])\n",
    "\n",
    "        # Search for best theoretical fit on your empirical data\n",
    "        model_results = dfit.fit_transform((los_df_diagnosis_mrs[\"los\"].dropna().values))\n",
    "\n",
    "        summary = dfit.summary.sort_values(\"score\")\n",
    "\n",
    "        best = summary.iloc[0]\n",
    "        best_score = best[\"score\"]\n",
    "\n",
    "        # tolerance rule\n",
    "        tolerance = 1.3  # 30% worse than best is acceptable\n",
    "\n",
    "        exp_row = summary[summary[\"name\"] == \"expon\"]\n",
    "\n",
    "\n",
    "        if not exp_row.empty:\n",
    "            exp_score = exp_row.iloc[0][\"score\"]\n",
    "\n",
    "            if best_score < ABSOLUTE_GOOD:\n",
    "                # Fits are indistinguishable → prefer exponential\n",
    "                chosen = exp_row.iloc[0]\n",
    "\n",
    "            elif exp_score <= RELATIVE_TOL * best_score:\n",
    "                chosen = exp_row.iloc[0]\n",
    "\n",
    "            else:\n",
    "                chosen = best\n",
    "        else:\n",
    "            chosen = best\n",
    "\n",
    "        results.append({\n",
    "            \"diagnosis\": diagnosis,\n",
    "            \"mrs\": mrs,\n",
    "            \"best_distribution\": chosen[\"name\"],\n",
    "            \"params\": chosen[\"params\"],\n",
    "            \"loc\": chosen[\"loc\"],\n",
    "            \"scale\": chosen[\"scale\"],\n",
    "            \"exp_score\": exp_row.iloc[0][\"score\"],\n",
    "            \"exp_score_diff_from_best\": exp_score - best_score,\n",
    "            \"score\": chosen[\"score\"],\n",
    "            \"best_score\": best_score,\n",
    "            \"score_ratio\": chosen[\"score\"] / best_score,\n",
    "            \"n_datapoints_fitted_on\": len(los_df_diagnosis_mrs),\n",
    "            \"min_los_observed\": los_df_diagnosis_mrs[\"los\"].min(),\n",
    "            \"median_los_observed\": los_df_diagnosis_mrs[\"los\"].median(),\n",
    "            \"mean_los_observed\": round(los_df_diagnosis_mrs[\"los\"].mean(),2),\n",
    "            \"max_los_observed\": los_df_diagnosis_mrs[\"los\"].max()\n",
    "\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values([\"diagnosis\", \"mrs\"])\n",
    "results_df[\"shape1\"] = results_df[\"params\"].apply(lambda x: x[0] if len(x) > 0 else None)\n",
    "results_df[\"shape2\"] = results_df[\"params\"].apply(lambda x: x[1] if len(x) > 1 else None)\n",
    "\n",
    "results_df.to_csv(\"los_params.csv\", index=False)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24631c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.show() for x in plots]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa498a76",
   "metadata": {},
   "source": [
    "# For MRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebee7f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "\n",
    "ich = los_df[los_df[\"diagnosis\"]==\"ICH\"][\"mrs\"].values\n",
    "i = los_df[los_df[\"diagnosis\"]==\"I\"][\"mrs\"].values\n",
    "\n",
    "fig = ff.create_distplot([ich,i], group_labels=[\"ICH\",\"I\"])\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bcf789",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for diagnosis in los_df[\"diagnosis\"].unique():\n",
    "\n",
    "    los_df_diagnosis = los_df[los_df[\"diagnosis\"]==diagnosis]\n",
    "\n",
    "    values = los_df_diagnosis[\"mrs\"].dropna().astype(int)\n",
    "\n",
    "    pmf = (\n",
    "        values\n",
    "        .value_counts(normalize=True)\n",
    "        .reindex(range(6), fill_value=0.0)\n",
    "    )\n",
    "\n",
    "    results.append({\n",
    "        \"diagnosis\": diagnosis,\n",
    "        \"mrs\": mrs,\n",
    "        \"distribution\": \"categorical\",\n",
    "        \"pmf\": pmf.to_dict(),\n",
    "        \"n_datapoints_fitted_on\": len(los_df_diagnosis),\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "pmf_df = (\n",
    "    results_df[\"pmf\"]\n",
    "    .apply(pd.Series)\n",
    "    .rename(columns=lambda x: f\"mrs_{int(x)}_prob\")\n",
    ")\n",
    "\n",
    "results_df = pd.concat([results_df.drop(columns=[\"pmf\"]), pmf_df], axis=1)\n",
    "results_df.to_csv(\"mrs_params.csv\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa3e3e4",
   "metadata": {},
   "source": [
    "Repeat without stratifying by diagnosis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348027c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "values = los_df[\"mrs\"].dropna().astype(int)\n",
    "\n",
    "pmf = (\n",
    "    values\n",
    "    .value_counts(normalize=True)\n",
    "    .reindex(range(6), fill_value=0.0)\n",
    ")\n",
    "\n",
    "results.append({\n",
    "    \"diagnosis\": diagnosis,\n",
    "    \"mrs\": mrs,\n",
    "    \"distribution\": \"categorical\",\n",
    "    \"pmf\": pmf.to_dict(),\n",
    "    \"n_datapoints_fitted_on\": len(los_df_diagnosis),\n",
    "})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "pmf_df = (\n",
    "    results_df[\"pmf\"]\n",
    "    .apply(pd.Series)\n",
    "    .rename(columns=lambda x: f\"mrs_{int(x)}_prob\")\n",
    ")\n",
    "\n",
    "results_df = pd.concat([results_df.drop(columns=[\"pmf\"]), pmf_df], axis=1)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0860fbda",
   "metadata": {},
   "source": [
    "# For Inter-arrival times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c256b7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "iat_df = pd.read_csv(iat_csv_file_path)\n",
    "\n",
    "results = []\n",
    "plots = []\n",
    "\n",
    "for time_period in [\"in-hours\",\"out-of-hours\"]:\n",
    "    time_period_df = iat_df[[time_period]].dropna()\n",
    "\n",
    "    fig = px.histogram(time_period_df, title=time_period)\n",
    "\n",
    "    plots.append(fig)\n",
    "\n",
    "    dfit = distfit(todf=True, distr=['norm', 'expon', 'pareto', 'weibull', 'gamma', 'lognorm', 'beta'])\n",
    "\n",
    "    # Search for best theoretical fit on your empirical data\n",
    "    model_results = dfit.fit_transform((time_period_df[time_period].dropna().values))\n",
    "\n",
    "    summary = dfit.summary.sort_values(\"score\")\n",
    "\n",
    "    best = summary.iloc[0]\n",
    "    best_score = best[\"score\"]\n",
    "\n",
    "    # tolerance rule\n",
    "    tolerance = 1.3  # 30% worse than best is acceptable\n",
    "\n",
    "    exp_row = summary[summary[\"name\"] == \"expon\"]\n",
    "\n",
    "    if not exp_row.empty:\n",
    "        exp_score = exp_row.iloc[0][\"score\"]\n",
    "\n",
    "        if best_score < ABSOLUTE_GOOD:\n",
    "            # Fits are indistinguishable → prefer exponential\n",
    "            chosen = exp_row.iloc[0]\n",
    "\n",
    "        elif exp_score <= RELATIVE_TOL * best_score:\n",
    "            chosen = exp_row.iloc[0]\n",
    "\n",
    "        else:\n",
    "            chosen = best\n",
    "    else:\n",
    "        chosen = best\n",
    "\n",
    "\n",
    "    results.append({\n",
    "        \"time_period\": time_period,\n",
    "        \"best_distribution\": chosen[\"name\"],\n",
    "        \"params\": chosen[\"params\"],\n",
    "        \"loc\": chosen[\"loc\"],\n",
    "        \"scale\": chosen[\"scale\"],\n",
    "        \"exp_score\": exp_row.iloc[0][\"score\"],\n",
    "        \"exp_score_diff_from_best\": exp_score - best_score,\n",
    "        \"score\": chosen[\"score\"],\n",
    "        \"best_score\": best_score,\n",
    "        \"score_ratio\": chosen[\"score\"] / best_score,\n",
    "        \"n_datapoints_fitted_on\": len(time_period_df),\n",
    "        \"min_iat_observed\": time_period_df[time_period].min(),\n",
    "        \"median_iat_observed\": time_period_df[time_period].median(),\n",
    "        \"mean_iat_observed\": time_period_df[time_period].mean(),\n",
    "        \"max_iat_observed\": time_period_df[time_period].max()\n",
    "\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df.to_csv(\"iat_params.csv\", index=False)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56a084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.show() for x in plots]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
